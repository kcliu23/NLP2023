{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgNZTjrhcHa0"
      },
      "source": [
        "## Lab#1, NLP Spring 2023\n",
        "\n",
        "### This is due on 2023/03/06 15:30, commit to your github as a PDF (lab1.pdf) (File>Print>Save as PDF). \n",
        "\n",
        "#### IMPORTANT: After copying this notebook to your Google Drive, please paste a link to it below. To get a publicly-accessible link, hit the *Share* button at the top right, then click \"Get shareable link\" and copy over the result. If you fail to do this, you will receive no credit for this lab!\n",
        "\n",
        "***LINK: *paste your link here****\n",
        "####https://colab.research.google.com/drive/15vN702ONpbn1CsKKX91tbux_z2repjKk?usp=sharing\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpg8eU9wNBci"
      },
      "source": [
        "**Student ID**:\n",
        "\n",
        "**Name**:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1_cCBOwfPxI"
      },
      "source": [
        "##Question 1 (100 points)\n",
        "Let's switch over to coding! Write some code in this cell to compute the number of unique word **tokens** in this paragraph (5 steps of Text Normalisation: 1. Lowercase Conversion, 2. Remove punctuations, 3. Stemming, 4. Lemmatisation, 5. Stopword Removal). Use a whitespace tokenizer to separate words (i.e., split the string by white space). Be sure that the cell's output is visible in the PDF file you turn in on Github.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "STVNzF0frsX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yjUfde9adfw",
        "outputId": "0f3edc8f-ad1a-41a1-a9e8-3012bc97b6c2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9Fm6AQJQDFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55a6fcab-5eb2-43eb-d9e8-fc9a38166228"
      },
      "source": [
        "paragraph = '''Last night I dreamed I went to Manderley again. It seemed to me\n",
        "that I was passing through the iron gates that led to the driveway.\n",
        "The drive was just a narrow track now, its stony surface covered\n",
        "with grass and weeds. Sometimes, when I thought I had lost it, it\n",
        "would appear again, beneath a fallen tree or beyond a muddy pool \n",
        "formed by the winter rains. The trees had thrown out new\n",
        "low branches which stretched across my way. I came to the house\n",
        "suddenly, and stood there with my heart beating fast and tears\n",
        "filling my eyes.'''\n",
        "\n",
        "# DO NOT MODIFY THE VARIABLES\n",
        "tokens = 0\n",
        "word_tokens = []\n",
        "\n",
        "# YOUR CODE HERE! POPULATE THE tokens and word_tokens VARIABLES WITH THE CORRECT VALUES!\n",
        "\n",
        "#Lowercase conversion\n",
        "paragraph = paragraph.lower()\n",
        "import nltk\n",
        "#nltk.download(\"punkt\")\n",
        "\n",
        "#remove punctuations\n",
        "def remove_punct(token):\n",
        "  return [word for word in token if word.isalpha()]\n",
        "paragraph = nltk.word_tokenize(paragraph)\n",
        "paragraph = remove_punct(paragraph)\n",
        "\n",
        "# print(paragraph)\n",
        "for word in paragraph:\n",
        "  if word not in word_tokens:\n",
        "    word_tokens.append(word)\n",
        "# print(word_tokens)\n",
        "\n",
        "#Stemming\n",
        "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer\n",
        "\n",
        "port = PorterStemmer()\n",
        "stemmed_port  = [port.stem(token) for token in word_tokens]\n",
        "\n",
        "lanc = LancasterStemmer()\n",
        "stemmed_lanc = [lanc.stem(token) for token in word_tokens]\n",
        "\n",
        "snow = SnowballStemmer(\"english\")\n",
        "stemmed_snow = [snow.stem(token) for token in word_tokens]\n",
        "#Lemmatisation\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "# nltk.download('wordnet')\n",
        "# nltk.download('omw-1.4')\n",
        "lemmatiser = WordNetLemmatizer()\n",
        "lemmatised = [lemmatiser.lemmatize(token) for token in word_tokens]\n",
        "\n",
        "#stopword removal\n",
        "from nltk.corpus import stopwords\n",
        "# nltk.download(\"stopwords\")\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "words_no_stop = [word for word in lemmatised if word not in stop_words]\n",
        "\n",
        "tokens = len(word_tokens)\n",
        "# DO NOT MODIFY THE BELOW LINE!\n",
        "print('Number of word tokens: %d' % (tokens))\n",
        "print(\"printing lists separated by space\")\n",
        "print(*word_tokens, sep = \" \") "
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of word tokens: 74\n",
            "printing lists separated by space\n",
            "last night i dreamed went to manderley again it seemed me that was passing through the iron gates led driveway drive just a narrow track now its stony surface covered with grass and weeds sometimes when thought had lost would appear beneath fallen tree or beyond muddy pool formed by winter rains trees thrown out new low branches which stretched across my way came house suddenly stood there heart beating fast tears filling eyes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rxOEfyAUkUp7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}