{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgNZTjrhcHa0"
      },
      "source": [
        "## Lab#1, NLP Spring 2023\n",
        "\n",
        "### This is due on 2023/03/06 15:30, commit to your github as a PDF (lab1.pdf) (File>Print>Save as PDF). \n",
        "\n",
        "#### IMPORTANT: After copying this notebook to your Google Drive, please paste a link to it below. To get a publicly-accessible link, hit the *Share* button at the top right, then click \"Get shareable link\" and copy over the result. If you fail to do this, you will receive no credit for this lab!\n",
        "\n",
        "***LINK: *paste your link here****\n",
        "####https://colab.research.google.com/drive/15vN702ONpbn1CsKKX91tbux_z2repjKk?usp=sharing\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpg8eU9wNBci"
      },
      "source": [
        "**Student ID**:\n",
        "\n",
        "**Name**:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1_cCBOwfPxI"
      },
      "source": [
        "##Question 1 (100 points)\n",
        "Let's switch over to coding! Write some code in this cell to compute the number of unique word **tokens** in this paragraph (5 steps of Text Normalisation: 1. Lowercase Conversion, 2. Remove punctuations, 3. Stemming, 4. Lemmatisation, 5. Stopword Removal). Use a whitespace tokenizer to separate words (i.e., split the string by white space). Be sure that the cell's output is visible in the PDF file you turn in on Github.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "STVNzF0frsX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "6yjUfde9adfw",
        "outputId": "0f3edc8f-ad1a-41a1-a9e8-3012bc97b6c2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph = '''Last night I dreamed I went to Manderley again. It seemed to me\n",
        "that I was passing through the iron gates that led to the driveway.\n",
        "The drive was just a narrow track now, its stony surface covered\n",
        "with grass and weeds. Sometimes, when I thought I had lost it, it\n",
        "would appear again, beneath a fallen tree or beyond a muddy pool \n",
        "formed by the winter rains. The trees had thrown out new\n",
        "low branches which stretched across my way. I came to the house\n",
        "suddenly, and stood there with my heart beating fast and tears\n",
        "filling my eyes.'''\n",
        "\n",
        "# DO NOT MODIFY THE VARIABLES\n",
        "tokens = 0\n",
        "word_tokens = []\n",
        "\n",
        "# YOUR CODE HERE! POPULATE THE tokens and word_tokens VARIABLES WITH THE CORRECT VALUES!\n",
        "\n",
        "#Lowercase conversion\n",
        "paragraph = paragraph.lower()\n",
        "import nltk\n",
        "#nltk.download(\"punkt\")\n",
        "\n",
        "#remove punctuations\n",
        "def remove_punct(token):\n",
        "  return [word for word in token if word.isalpha()]\n",
        "paragraph = nltk.word_tokenize(paragraph)\n",
        "paragraph = remove_punct(paragraph)\n",
        "\n",
        "# print(paragraph)\n",
        "for word in paragraph:\n",
        "  if word not in word_tokens:\n",
        "    word_tokens.append(word)\n",
        "# print(word_tokens)\n",
        "\n",
        "#stopword removal\n",
        "from nltk.corpus import stopwords\n",
        "# nltk.download(\"stopwords\")\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "word_tokens = [word for word in word_tokens if word not in stop_words]\n",
        "\n",
        "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer\n",
        "\n",
        "port = PorterStemmer()\n",
        "stemmed_port  = [port.stem(token) for token in word_tokens]\n",
        "# print(stemmed_port)\n",
        "lanc = LancasterStemmer()\n",
        "stemmed_lanc = [lanc.stem(token) for token in word_tokens]\n",
        "\n",
        "snow = SnowballStemmer(\"english\")\n",
        "stemmed_snow = [snow.stem(token) for token in word_tokens]\n",
        "#Lemmatisation\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "# nltk.download('wordnet')\n",
        "# nltk.download('omw-1.4')\n",
        "lemmatiser = WordNetLemmatizer()\n",
        "word_tokens = [lemmatiser.lemmatize(token) for token in stemmed_port]\n",
        "\n",
        "\n",
        "tokens = len(word_tokens)\n",
        "# DO NOT MODIFY THE BELOW LINE!\n",
        "print('Number of word tokens: %d' % (tokens))\n",
        "print(\"printing lists separated by space\")\n",
        "print(*word_tokens, sep = \" \") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "IzvXqqrA7Jjh",
        "outputId": "b9c62789-d401-4c70-b214-fe57da5fcb44"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of word tokens: 51\n",
            "printing lists separated by space\n",
            "last night dream went manderley seem pas iron gate led driveway drive narrow track stoni surfac cover grass weed sometim thought lost would appear beneath fallen tree beyond muddi pool form winter rain tree thrown new low branch stretch across way came hous suddenli stood heart beat fast tear fill eye\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AZ_qEupi7PkY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}